* TODO Determine how to use a predict function with 'caret' for uncert_sampling
* TODO Test that uncert_sampling works using iris data set.
* TODO From above test, implement a unit test for uncert_sampling
* TODO Update documentation in uncert_sampling to describe the usage of 'caret'
* TODO Implement the usage of 'caret' in query_by_bagging
* TODO Test that query_by_bagging works using iris data set.
* TODO From above test, implement a unit test for query_by_bagging
* TODO Update documentation in query_by_bagging to describe the usage of 'caret'
* TODO Implement the usage of 'caret' in query_by_committee
* TODO Test that query_by_committee works using iris data set.
* TODO From above test, implement a unit test for query_by_committee
* TODO Update documentation in query_by_committee to describe the usage of 'caret'
* TODO Add a function that generates the experimental setup for active learning.

Details?

* TODO Run activelearning code with Power Grid data
* TODO Generate error rate curves as a function of number of labels
* TODO Build the package vignette through R.
** Link: http://www.statistik.lmu.de/~leisch/Sweave/Sweave-Rnews-2003-2.pdf
* TODO After the query_by_committee setup is determined, update its @examples to reflect the changes.
* TODO When returning results from the active learning functions, consider the following:
** Rather than returning the 'obs_uncertainty' or something just as obscure,
consider naming this the same as the uncertainty or disagreement measure.
** Example: If we are considering 'entropy' in uncert_sampling(), then return
'entropy' as a list component instead of 'obs_uncertainty'
* TODO Remove ~/projects/active-learning after double-checking that I have the report backed up in this package's /inst/
