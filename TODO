Add some more to the active learning vignette
With the Iris data set
	Look at Uncertainty Sampling, Query by Bagging, and Query by Committee


Iris Data Set
	Classifiers
		Consider LDA, QDA, SVM (with RBF), and RF
			Do this with 'caret'
	Oracle Setup
		The oracle is infallible.
		Query 1 and 5 observations each time until done.
	Active Learning Methods
		Random query
		Uncertainty Sampling with Iris Data Set
			Use the 3 uncertainty sampling methods
		Query by Bagging
			Try B = 10, 50, and 100
		(Optional) Query by Committee
Add a function that generates the experimental setup for active learning.

Move the vignette to ./inst/doc
	After adding the initial simulation code to the vignette
Build the package vignette through R.
	Link: http://www.statistik.lmu.de/~leisch/Sweave/Sweave-Rnews-2003-2.pdf

Simulation
	Find 3 benchmark data sets and compare the methods.
		For now, use Iris and two data sets on UCI Machine Learning Repository.
	Pick 5-10(-ish) supervised classifiers.
	Compare the supervised classifiers in the query-by-bagging approach with say B = 10, 50, and 100.
		Compare them with each disagreement measure.
		In webnotebook, create a plot for each B.
	Also, compare the 10 classifiers in the query-by-committee approach.
		Compare them with each disagreement measure.
	Need a text classification data set in the actual paper since that is the application of most AL methods.
	At some point, need to find a benchmark data set with at least one time-dependent covariate.
		Do the methods still work with time-dependent covariates?




Throw an error if the "uncertainty" measure is incorrect in uncert_sampling().
 Write a unit test to catch this.
Throw an error if the "disagreement" measure is incorrect in query_by_bagging().
 Write a unit test to catch this.
When returning results from the active learning functions, consider the following:
	Rather than returning the 'obs_uncertainty' or something just as obscure,
	consider naming this the same as the uncertainty or disagreement measure.
	Example: If we are considering 'entropy' in uncert_sampling(), then return
	'entropy' as a list component instead of 'obs_uncertainty'

Add note that we may be able to weight the Bayesian information density with a power prior.
